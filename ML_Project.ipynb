{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ashim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('C:\\\\Users\\\\ashim\\\\Downloads\\\\reviews.tsv', delimiter = '\\t')\n",
    "\n",
    "import re   #checks if a particular string matches a given regular expression \n",
    "import nltk    #Natural Language Toolkit; for building Python programs to work with human language data\n",
    "\n",
    "nltk.download('stopwords')    \n",
    "\n",
    "from nltk.corpus import stopwords   #collection of commonly used words (such as “the”, “a”, “an”, “in”) \n",
    "from nltk.stem.porter import PorterStemmer   #removing the commoner inflexion endings from words, extract root word( ed,est)\n",
    "ps = PorterStemmer()   \n",
    "\n",
    "all_stopwords = stopwords.words('english')  #list of all the English stop words supported by NLTK\n",
    "all_stopwords.remove('not')   #Removing not from stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "\n",
    "for i in range(0, 900):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])   #[^_] negates a character match inside square brackets, i.e. the characters apart from a-z and A-Z and substitute them with a blank \" \"\n",
    "  review = review.lower()   # returns the lowercased strings\n",
    "  review = review.split()   # splits a string into a list\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)  \n",
    "  words.append(review)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "cv = CountVectorizer(max_features = 1420)   #CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(words).toarray()   \n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter.ttk import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import linear_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(root, input):\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)   \n",
    "\n",
    "    data = [input]\n",
    "    vectorizer = cv.transform(data).toarray()\n",
    "    pred = classifier.predict(vectorizer)\n",
    "    if pred==0 :\n",
    "        gaus= Label(root, text='Bad  review', font=\"times 15\").place(relx= 0.45, rely=0.4)\n",
    "    else:\n",
    "        gaus= Label(root, text='Good review', font=\"times 15\").place(relx= 0.45, rely=0.4)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinom(root, input):\n",
    "    classifier = MultinomialNB(alpha=0.1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    data = [input]\n",
    "    vectorizer = cv.transform(data).toarray()\n",
    "    pred = classifier.predict(vectorizer)\n",
    "    if pred==0 :\n",
    "        Label(root, text='Bad  review', font=\"times 15\").place(relx= 0.45, rely=0.5)\n",
    "    else:\n",
    "        Label(root, text='Good review', font=\"times 15\").place(relx= 0.45, rely=0.5)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli(root, input):\n",
    "    # Bernoulli NB\n",
    "\n",
    "    # Fitting Naive Bayes to the Training set\n",
    "    classifier = BernoulliNB(alpha=0.8)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    data = [input]\n",
    "    vectorizer = cv.transform(data).toarray()\n",
    "    pred = classifier.predict(vectorizer)\n",
    "    if pred==0 :\n",
    "        Label(root, text='Bad  review', font=\"times 15\").place(relx= 0.45, rely=0.6)\n",
    "    else:\n",
    "        Label(root, text='Good review', font=\"times 15\").place(relx= 0.45, rely=0.6)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(root, input):\n",
    "    # Logistic Regression\n",
    "\n",
    "    # Fitting Logistic Regression to the Training set\n",
    "    classifier = linear_model.LogisticRegression(C=1.5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    data = [input]\n",
    "    vectorizer = cv.transform(data).toarray()\n",
    "    pred = classifier.predict(vectorizer)\n",
    "    if pred==0 :\n",
    "        log= Label(root,text= 'Bad  review', font=\"times 15\").place(relx= 0.45, rely=0.7)\n",
    "        \n",
    "    else:\n",
    "        log= Label(root,text= 'Good review', font=\"times 15\").place(relx= 0.45, rely=0.7)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaus_acc(root):\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)   \n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    score1 = accuracy_score(y_test,y_pred)\n",
    "    score2 = precision_score(y_test,y_pred)\n",
    "    score3= recall_score(y_test,y_pred)\n",
    "    \n",
    "    Label(root,text= round(score1*100,2), relief=\"solid\").place(relx= 0.85, rely=0.45)\n",
    "    Label(root,text= round(score2*100,2), relief=\"solid\").place(relx= 0.85, rely=0.55)\n",
    "    Label(root,text= round(score3*100,2), relief=\"solid\").place(relx= 0.85, rely=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_acc(root):\n",
    "    classifier = MultinomialNB(alpha=0.1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    score1 = accuracy_score(y_test,y_pred)\n",
    "    score2 = precision_score(y_test,y_pred)\n",
    "    score3= recall_score(y_test,y_pred)\n",
    "\n",
    "    Label(root,text= round(score1*100,2), relief=\"solid\").place(relx= 0.85, rely=0.45)\n",
    "    Label(root,text= round(score2*100,2), relief=\"solid\").place(relx= 0.85, rely=0.55)\n",
    "    Label(root,text= round(score3*100,2), relief=\"solid\").place(relx= 0.85, rely=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bern_acc(root):\n",
    "    # Making the Confusion Matrix\n",
    "    classifier = BernoulliNB(alpha=0.8)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    score1 = accuracy_score(y_test,y_pred)\n",
    "    score2 = precision_score(y_test,y_pred)\n",
    "    score3= recall_score(y_test,y_pred)\n",
    "\n",
    "    Label(root,text= round(score1*100,2), relief=\"solid\").place(relx= 0.85, rely=0.45)\n",
    "    Label(root,text= round(score2*100,2), relief=\"solid\").place(relx= 0.85, rely=0.55)\n",
    "    Label(root,text= round(score3*100,2), relief=\"solid\").place(relx= 0.85, rely=0.65)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_acc(root):\n",
    "    classifier = linear_model.LogisticRegression(C=1.5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    score1 = accuracy_score(y_test,y_pred)\n",
    "    score2 = precision_score(y_test,y_pred)\n",
    "    score3= recall_score(y_test,y_pred)\n",
    "\n",
    "    Label(root,text= round(score1*100,2), relief=\"solid\").place(relx= 0.85, rely=0.45)\n",
    "    Label(root,text= round(score2*100,2), relief=\"solid\").place(relx= 0.85, rely=0.55)\n",
    "    Label(root,text= round(score3*100,2), relief=\"solid\").place(relx= 0.85, rely=0.65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2():\n",
    "    input = rev.get()\n",
    "    # print(input)\n",
    "    gaussian(main_window, input)\n",
    "    multinom(main_window, input)\n",
    "    bernoulli(main_window, input)\n",
    "    logistic(main_window, input)  \n",
    "\n",
    "def gaus_acc2():\n",
    "    gaus_acc(main_window)\n",
    "\n",
    "def mult_acc2():\n",
    "    mult_acc(main_window)\n",
    "\n",
    "def bern_acc2():\n",
    "    bern_acc(main_window)\n",
    "\n",
    "def log_acc2():\n",
    "    log_acc(main_window)\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "\n",
    "main_window= Tk()\n",
    "\n",
    "main_window.geometry(\"900x600\")\n",
    "main_window['background']='#99ff99'\n",
    "\n",
    "Label(main_window, text=\"Review Sentiment Predictor\", font=\"times 15 bold\").place(relx= 0.19, rely=0.08)\n",
    "\n",
    "Label(main_window, text=\"Enter a review:\", font=\"times 15 bold\").place(relx= 0.1, rely=0.2)\n",
    "\n",
    "rev= ttk.Entry(main_window,width=40)\n",
    "rev.place(relx=0.3, rely=0.2)\n",
    "\n",
    "Button(main_window,text=\"Submit\",command =evaluate2).place(relx=0.3, rely= 0.3)\n",
    "\n",
    "Label(main_window, text= \"Prediction using Gaussian Model\", font=\"times 15 bold\").place(relx=0.1, rely=0.4)\n",
    "Label(main_window, text= \"Prediction using Multinomial Model\", font=\"times 15 bold\",).place(relx=0.1, rely=0.5)\n",
    "Label(main_window, text= \"Prediction using Bernoulli Model\", font=\"times 15 bold\").place(relx=0.1, rely=0.6)\n",
    "Label(main_window, text= \"Prediction using Logistic Model\", font=\"times 15 bold\").place(relx=0.1, rely=0.7)\n",
    "\n",
    "Label(main_window, text = \"Check Accuracy of models\",font=\"times 15 bold\").place(relx= 0.7, rely= 0.08)\n",
    "\n",
    "Button(main_window, text = \"Gaussian\", command= gaus_acc2).place(relx= 0.7, rely= 0.2)\n",
    "Button(main_window, text = \"Multinomial\", command= mult_acc2).place(relx= 0.7, rely= 0.3)\n",
    "Button(main_window, text = \"Bernoulli\", command=bern_acc2).place(relx= 0.8, rely= 0.2)\n",
    "Button(main_window, text = \"Logistic\",command= log_acc2).place(relx= 0.8, rely= 0.3)\n",
    "\n",
    "\n",
    "Label(main_window, text= \"Accuracy\", font=\"times 15 bold underline\").place(relx=0.7, rely=0.45)\n",
    "Label(main_window, text= \"Precision\", font=\"times 15 bold underline\").place(relx=0.7, rely=0.55)\n",
    "Label(main_window, text= \"Recall\", font=\"times 15 bold underline\").place(relx=0.7, rely=0.65)\n",
    "\n",
    "main_window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c08fcd23c77bfb5ee56d1a6f1427620e609d2a5b71021227ea509b0443ab141b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
